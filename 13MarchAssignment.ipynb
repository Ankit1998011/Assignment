{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a5a27e0-8966-41d9-9b1b-7fea3af7af08",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.\n",
    "\n",
    "Ans.\n",
    "\n",
    "Analysis of Variance (ANOVA) is a statistical method that is used to compare means among three or more groups. In order to use ANOVA, there are several assumptions that must be met:\n",
    "\n",
    "1.Normality: The data should be normally distributed within each group.\n",
    "\n",
    "2.Homogeneity of variance: The variance of the data within each group should be approximately equal.\n",
    "\n",
    "3.Independence: The observations in each group should be independent of each other.\n",
    "\n",
    "If any of these assumptions are violated, the results of the ANOVA may be invalid or biased. \n",
    "\n",
    "Examples of violations that could impact the validity of the results include:\n",
    "\n",
    "1.Non-normality: If the data within a group is not normally distributed, then the ANOVA results may be unreliable. For example, if the data is skewed or has outliers, it may violate the assumption of normality.\n",
    "\n",
    "2.Heterogeneity of variance: If the variance of the data within a group is not equal, then the ANOVA results may be misleading. For example, if one group has much higher variance than the other groups, it can result in a false conclusion that the means of the groups are significantly different.\n",
    "\n",
    "3.Dependence: If the observations within a group are not independent, then the ANOVA results may be biased. For example, if measurements are taken on the same subjects over time, there may be correlations between the measurements that violate the assumption of independence.\n",
    "\n",
    "4.Sample size: The ANOVA results can be sensitive to sample size, especially if the sample sizes are unequal. If the sample sizes are too small, the statistical power of the analysis may be too low to detect real differences between groups. \n",
    "\n",
    "Overall, it is important to check the assumptions of ANOVA before using this method, and if any violations are present, alternative methods should be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c7c380-ded8-4f8f-877e-4b284c35212a",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2fa6d2-3871-41f0-ae17-03b13020faea",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "Ans. \n",
    "\n",
    "The three types of ANOVA are one-way ANOVA, two-way ANOVA, and repeated measures ANOVA.\n",
    "\n",
    "1.One-way ANOVA: One-way ANOVA is used when there is only one independent variable with three or more levels or groups. It is used to determine if there are any significant differences between the means of these groups. For example, if we want to compare the mean weight of different breeds of dogs (e.g., Labrador, German Shepherd, Poodle), we could use one-way ANOVA.\n",
    "\n",
    "2.Two-way ANOVA: Two-way ANOVA is used when there are two independent variables, also known as factors. It is used to determine if there is an interaction effect between these factors and if there are any main effects. For example, if we want to compare the mean weight of different breeds of dogs based on their gender (male vs. female) and age (young vs. old), we could use two-way ANOVA.\n",
    "\n",
    "3.Repeated measures ANOVA: Repeated measures ANOVA is used when there are repeated measures on the same subject or group of subjects over time or under different conditions. It is used to determine if there is a significant difference between the means of these measures. For example, if we want to compare the mean weight of a group of dogs at different ages (1 year, 2 years, 3 years), we could use repeated measures ANOVA.\n",
    "\n",
    "In summary, one-way ANOVA is used when there is only one independent variable, two-way ANOVA is used when there are two independent variables, and repeated measures ANOVA is used when there are repeated measures on the same subject or group of subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87164170-c91e-4707-ba1b-c8d023dbdb5c",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b335a39-bbf1-47ff-8f1c-21b3138b2a05",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "Ans. \n",
    "\n",
    "The partitioning of variance is a concept used in ANOVA to explain the sources of variation in the data. In ANOVA, the total variation in the data is divided into two parts: the variation between groups and the variation within groups. The partitioning of variance is important because it allows us to quantify the amount of variation that can be attributed to the factors or independent variables being tested, and the amount that cannot be explained by these factors. This is useful because it helps us determine if there is a significant difference between the means of the groups being compared.\n",
    "\n",
    "The partitioning of variance is typically represented in ANOVA tables, which show the sum of squares (SS), degrees of freedom (df), mean squares (MS), F-ratio, and p-value. The total sum of squares (SST) represents the total variation in the data, the sum of squares between (SSB) represents the variation between groups, and the sum of squares within (SSW) represents the variation within groups. \n",
    "\n",
    "The F-ratio is calculated as the ratio of the mean square between to the mean square within, and it measures the amount of variation between groups relative to the amount of variation within groups. The p-value represents the probability of obtaining a F-ratio as extreme as the one observed, assuming that there is no significant difference between the means of the groups being compared.\n",
    "\n",
    "Understanding the partitioning of variance is important because it helps us interpret the results of ANOVA and determine if there is a significant difference between the means of the groups being compared. It also helps us identify which factors or independent variables are contributing to the variation in the data, and can guide us in further analysis or experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad4ffcb-f03a-41ff-9bb6-ca8560d4b890",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56f4372-ec0e-465b-8d72-0400f309d12a",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "\n",
    "\n",
    "Ans.\n",
    "\n",
    "To calculate SST, SSE, and SSR for a one-way ANOVA in Python, we can use the 'statsmodels' library. Here is an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e04e13-f1de-446a-95c6-145c2c010f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST = 17.5\n",
      "SSE = 16.0\n",
      "SSR = 1.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a sample dataset\n",
    "df = pd.DataFrame({'group': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "                   'value': [1, 2, 3, 4, 5, 6]})\n",
    "\n",
    "# Fit the one-way ANOVA model\n",
    "model = ols('value ~ group', data=df).fit()\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "grand_mean = df['value'].mean()\n",
    "df['grand_mean'] = grand_mean\n",
    "df['deviation'] = (df['value'] - grand_mean)**2\n",
    "SST = df['deviation'].sum()\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "group_mean = df.groupby('group')['value'].mean()\n",
    "df = df.join(group_mean, on='group', rsuffix='_group')\n",
    "df['group_deviation'] = (df['value_group'] - grand_mean)**2\n",
    "SSE = df['group_deviation'].sum()\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print('SST =', SST)\n",
    "print('SSE =', SSE)\n",
    "print('SSR =', SSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f9587e-d698-4dda-a787-6dec9103cf4a",
   "metadata": {},
   "source": [
    "In this example, we first create a sample dataset with three groups ('A', 'B', and 'C') and their corresponding values. We then fit a one-way ANOVA model using the 'ols' function from 'statsmodels.formula.api'. \n",
    "\n",
    "To calculate SST, we first calculate the grand mean of all the values and then calculate the deviation of each value from the grand mean. We sum up the squared deviations to get SST.\n",
    "\n",
    "To calculate SSE, we first calculate the mean value for each group and then calculate the deviation of each group mean from the grand mean. We sum up the squared deviations to get SSE.\n",
    "\n",
    "Finally, we calculate SSR by subtracting SSE from SST.\n",
    "\n",
    "Note that in this example, we manually calculated SST, SSE, and SSR using the formulas. However, 'statsmodels' also provides these values in the ANOVA table output, which can be accessed using the 'anova_lm' function:\n",
    "\n",
    "This will print the ANOVA table, which includes the sum of squares, degrees of freedom, mean square, F-value, and p-value for each source of variation. The 'typ=2' argument specifies the type of sum of squares calculation to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508d68a4-8d0c-4c39-b6c0-ebc5fb3c119b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          sum_sq   df     F    PR(>F)\n",
      "group       16.0  2.0  16.0  0.025095\n",
      "Residual     1.5  3.0   NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5479db46-10e2-4420-a13d-7abaecc5a918",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203d48bb-ffd1-4408-9c97-262be64b6420",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "\n",
    "Ans. To calculate the main effects and interaction effects in a two-way ANOVA using Python, you can use the `statsmodels` library. Here is an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2246ec9-1de4-494f-ae82-684500a3a8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects: Intercept         1.0\n",
      "C(group1)[T.B]    2.0\n",
      "dtype: float64\n",
      "Interaction effect: 3.9999999999999996\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a sample dataset\n",
    "df = pd.DataFrame({'group1': ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D'],\n",
    "                   'group2': ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
    "                   'value': [1, 2, 3, 4, 5, 6, 7, 8]})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('value ~ C(group1) + C(group2) + C(group1):C(group2)', data=df).fit()\n",
    "\n",
    "# Calculate the main effects\n",
    "main_effects = model.params[:2]\n",
    "\n",
    "# Calculate the interaction effect\n",
    "interaction_effect = model.params[2]\n",
    "\n",
    "print('Main effects:', main_effects)\n",
    "print('Interaction effect:', interaction_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca0e470-09f0-4520-9e2e-2ecde5ed335d",
   "metadata": {},
   "source": [
    "In this example, we first create a sample dataset with two grouping variables ('group1' and 'group2') and their corresponding values. We then fit a two-way ANOVA model using the 'ols' function from 'statsmodels.formula.api'. \n",
    "\n",
    "To calculate the main effects, we extract the first two parameters from the model output, which represent the estimated means for each group of the two grouping variables. We store them in the 'main_effects' variable.\n",
    "\n",
    "To calculate the interaction effect, we extract the third parameter from the model output, which represents the estimated mean difference between the two grouping variables when they are combined. We store it in the 'interaction_effect' variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae346ccb-34dd-421a-a41e-ae3132153dd4",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d75154-3ef1-4f73-9932-0c139a8a2f63",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?\n",
    "\n",
    "Ans. If we conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, we can conclude that there is a significant difference between at least two of the groups.\n",
    "\n",
    "The F-statistic measures the ratio of the variance between groups to the variance within groups. A larger F-statistic indicates that the differences between the group means are larger relative to the variation within the groups. In this case, the F-statistic of 5.23 indicates that the between-group variance is greater than the within-group variance.\n",
    "\n",
    "The p-value measures the probability of obtaining the observed F-statistic or a more extreme value if there is no true difference between the groups. In this case, the p-value of 0.02 indicates that the probability of obtaining an F-statistic of 5.23 or larger if there is no true difference between the groups is only 2%. This is a relatively small probability, so we can reject the null hypothesis and conclude that there is a significant difference between at least two of the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1f5a15-6907-4dd1-bc07-6f42343c9bbd",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab59f1a1-bbf8-410d-9052-06e116431e15",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?\n",
    "\n",
    "Ans.\n",
    "\n",
    "In a repeated measures ANOVA, missing data can be handled using several methods, including:\n",
    "\n",
    "1.Complete case analysis: This involves only including participants who have complete data for all time points. This is the most straightforward method but may result in a loss of power if there are a large number of missing observations.\n",
    "\n",
    "2.Last observation carried forward (LOCF): This involves replacing missing values with the last observed value for that participant. This method assumes that the missing value is the same as the last observed value, which may not always be accurate.\n",
    "\n",
    "3.Multiple imputation: This involves creating multiple plausible values for missing data and analyzing each imputed dataset separately. The results are then combined to obtain a single set of estimates. This method can provide unbiased estimates but may be computationally intensive and requires making assumptions about the missing data mechanism.\n",
    "\n",
    "The potential consequences of using different methods to handle missing data include:\n",
    "\n",
    "1.Bias: If the missing data are not missing completely at random (MCAR) and the missingness is related to the outcome variable or other predictors, using complete case analysis or LOCF may result in biased estimates.\n",
    "\n",
    "2.Increased variability: If the missing data are MCAR and there is a large amount of missing data, using complete case analysis may result in increased variability and reduced power.\n",
    "\n",
    "3.Incorrect standard errors: If the missing data are not MCAR and there is a large amount of missing data, using complete case analysis or LOCF may result in incorrect standard errors, leading to incorrect hypothesis testing.\n",
    "\n",
    "4.Loss of power: If the missing data are MCAR and there is a large amount of missing data, using multiple imputation may result in a loss of power due to the need to create multiple imputed datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae68e21c-cdc8-47d6-8688-f4ec3f0f37b2",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34466d0-8fa1-4d14-85cf-36ef579e7f4f",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "Ans. Post-hoc tests are used after an ANOVA to determine which specific groups differ significantly from each other. There are several common post-hoc tests used after ANOVA, including:\n",
    "\n",
    "1.Tukey's Honestly Significant Difference (HSD) test: This test is used to compare all possible pairs of means and adjust for multiple comparisons. It is typically used when there are more than two groups.\n",
    "\n",
    "2.Bonferroni correction: This test is used to control the familywise error rate by adjusting the significance level for each individual comparison. It is often used when there are a large number of pairwise comparisons.\n",
    "\n",
    "3.Scheffe's test: This test is a conservative test that controls the familywise error rate and can be used when the number of comparisons is not known in advance.\n",
    "\n",
    "4.Dunnett's test: This test is used to compare each treatment group to a control group and adjust for multiple comparisons. It is often used when there is a single control group and multiple treatment groups.\n",
    "\n",
    "The choice of post-hoc test depends on the specific research question and the study design. Tukey's HSD test is often used when there are more than two groups, while Dunnett's test is appropriate when there is a single control group. Bonferroni correction is generally more conservative than Tukey's HSD test and is often used when there are a large number of pairwise comparisons.\n",
    "\n",
    "An example of a situation where a post-hoc test might be necessary is a study comparing the effects of three different types of exercise on cardiovascular health. After performing an ANOVA and finding a significant main effect, a post-hoc test such as Tukey's HSD could be used to determine which types of exercise differ significantly from each other. This information could be useful in developing targeted exercise programs for different populations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d7c18b-3f70-44d7-9fa1-12b53bc24662",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b190dcc-6ae8-4c34-be88-3b57ee6d570f",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results.\n",
    "\n",
    "\n",
    "Ans.\n",
    "\n",
    "Null Hypothesis(H0):- muA = muB = muC  i.e. their is no significant differences between the mean weight loss of three diets.\n",
    "\n",
    "Alternate Hypothesis(H1):- Their is significant difference between the mean weight loss of three diets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f8a4138-565e-4028-a913-313fa208229c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistics: 38.1814612681822\n",
      "P-value: 4.4208876104953276e-14\n"
     ]
    }
   ],
   "source": [
    "# Solution:-\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "A = np.random.normal(5, 1, 50)\n",
    "B = np.random.normal(6, 1, 50)\n",
    "C = np.random.normal(4, 1, 50)\n",
    "\n",
    "f_val, p_val = stat.f_oneway(A, B, C)\n",
    "\n",
    "print(f\"F-statistics: {f_val}\")\n",
    "print(f\"P-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a9f57a-1ff3-425d-ae4b-2f5df7f01faa",
   "metadata": {},
   "source": [
    "Since, P-value is very small we can reject the Null Hypothesis and can conclude that their is  significant differences between the mean weight loss of three diets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8cfcf5-445a-470e-9821-ba8b755a182f",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b7910d-d328-442b-95a5-4d279300f8ce",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "\n",
    "Ans.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8356457c-5ad9-4850-8990-5e1d389a6d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        sum_sq    df         F    PR(>F)\n",
      "Program               2.926855   2.0  0.264784  0.768009\n",
      "Experience            3.094719   1.0  0.559941  0.456374\n",
      "Program:Experience    3.334259   2.0  0.301641  0.740401\n",
      "Residual            464.256575  84.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate random task completion time data for 30 employees in each program and experience level\n",
    "np.random.seed(123)\n",
    "data = pd.DataFrame({\n",
    "    'Time': np.random.normal(10, 2, 90),\n",
    "    'Program': np.repeat(['A', 'B', 'C'], 30),\n",
    "    'Experience': np.tile(['Novice', 'Experienced'], 45)\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ Program + Experience + Program:Experience', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print results\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3039a03b-a3a1-4594-8891-13df4428dd87",
   "metadata": {},
   "source": [
    "The ANOVA table shows the sum of squares, degrees of freedom, F-statistic, and p-value for each effect, as well as the residual sum of squares and degrees of freedom.\n",
    "\n",
    "The F-statistic for the main effect of program is 0.264784 with a large p-value of 0.768009, indicating that there is not significant difference in the average task completion time between the three software programs. This suggests that the software programs used doesn't have an effect on task completion time.\n",
    "\n",
    "The F-statistic for the main effect of experience is 0.559941 with a relatively large p-value of 0.456374, indicating that there is not a significant difference in the average task completion time between novice and experienced employees. This suggests that employee experience level does not have a significant effect on task completion time.\n",
    "\n",
    "The F-statistic for the interaction effect between program and experience is 0.301641 with a large p-value of 0.740401, indicating that there is not a significant interaction effect between program and experience on task completion time. This suggests that the effect of the software program on task completion time does not depend on the employee's experience level.\n",
    "\n",
    "In conclusion, we found that the software program used doesn't has a significant effect on task completion time, while employee experience level does not. Additionally, we found no significant interaction effect between program and experience on task completion time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b96a89-d96a-4def-a46c-a0298f4a6463",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebfd36a-5021-4dea-9c4f-6a31d7331545",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student testscores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other.\n",
    "\n",
    "Ans.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a1d751d-e65a-454a-8368-0c29d1df3032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -3.032\n",
      "p-value: 0.003\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Generate random test scores data for 100 students in each group\n",
    "np.random.seed(123)\n",
    "control_scores = np.random.normal(70, 10, 100)\n",
    "experimental_scores = np.random.normal(75, 10, 100)\n",
    "\n",
    "# Perform the two-sample t-test\n",
    "t_stat, p_val = ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"t-statistic: {:.3f}\".format(t_stat))\n",
    "print(\"p-value: {:.3f}\".format(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bb4355-972d-4968-8a43-28d5bfa7ac6c",
   "metadata": {},
   "source": [
    "The t-test results show that the t-statistic is -3.032 with a p-value of 0.003, which is less than the significance level of 0.05. This indicates that there is a significant difference in test scores between the control and experimental groups. Specifically, the experimental group has a higher mean test score than the control group.\n",
    "\n",
    "To determine which group(s) differ significantly from each other, we can use post-hoc tests. One commonly used post-hoc test is the Tukey's Honestly Significant Difference (HSD) test. Here's an example code that performs the Tukey's HSD test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fca54a99-30ab-4deb-b3f7-f6f7bbfdaf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental   4.5336 0.0028 1.5846 7.4826   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Combine the control and experimental data into a single array\n",
    "scores = np.concatenate([control_scores, experimental_scores])\n",
    "\n",
    "# Create a grouping variable indicating the control and experimental groups\n",
    "groups = np.concatenate([np.repeat('Control', 100), np.repeat('Experimental', 100)])\n",
    "\n",
    "# Perform the Tukey's HSD test\n",
    "tukey_results = pairwise_tukeyhsd(scores, groups, alpha=0.05)\n",
    "\n",
    "# Print the results\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9ba24a-fdfb-442a-af7e-333221433499",
   "metadata": {},
   "source": [
    "The Tukey's HSD test results show that there is a significant difference between the control and experimental groups with a mean difference of 4.5336 and a p-value of 0.0028. This confirms that the experimental group has a significantly higher mean test score than the control group.\n",
    "\n",
    "In conclusion, we found that the new teaching method significantly improves student test scores compared to the traditional teaching method. The Tukey's HSD test indicated that the experimental group had a significantly higher mean test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec0d705-6156-40f4-966f-dc56ac919cef",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb0ca3b-5ccd-4384-8959-8ed8775daf5f",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other.\n",
    "\n",
    "Ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92fd72a2-3873-4053-ba5b-c42a799ca7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               sum_sq    df         F    PR(>F)\n",
      "store        0.288889   2.0  0.049258  0.951963\n",
      "day          7.475009   1.0  2.549104  0.114112\n",
      "store:day    7.302855   2.0  1.245198  0.293142\n",
      "Residual   246.322136  84.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create a sample data frame\n",
    "data = pd.DataFrame({\n",
    "    'store': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
    "    'day': list(range(1, 31)) * 3,\n",
    "    'sales': [10, 8, 11, 9, 12, 13, 8, 10, 7, 11,\n",
    "              9, 10, 12, 13, 14, 8, 11, 10, 9, 12,\n",
    "              10, 9, 11, 12, 10, 11, 13, 12, 14, 11,\n",
    "              9, 8, 10, 11, 13, 12, 8, 10, 9, 11,\n",
    "              12, 11, 9, 10, 11, 12, 13, 11, 10, 9,\n",
    "              14, 12, 10, 9, 11, 8, 12, 13, 11, 10,\n",
    "              8, 9, 11, 12, 13, 12, 10, 11, 9, 8,\n",
    "             14, 12, 10, 9, 11, 8, 12, 13, 11, 10,\n",
    "              8, 9, 11, 12, 13, 12, 10, 11, 9, 8]\n",
    "})\n",
    "\n",
    "# perform repeated measures ANOVA\n",
    "rm = ols('sales ~ store + day + store:day', data=data).fit()\n",
    "table = sm.stats.anova_lm(rm, typ=2)\n",
    "\n",
    "# print the ANOVA table\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6354c381-9f46-4cdc-a371-e30ceeb03710",
   "metadata": {},
   "source": [
    "Since, P-val is 0.951963 is > 0.05 we can conclude there is not any significant differences in sales between the three stores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
